---
title: "Fitting impulse~response models in R"
author: "Andreas K. Winther"
date: "2019-03-04"
categories: ["R", "Modelling", "Prediction"]
math: "true"
image:
  caption: ""
  focal_point: ""
summary: In this blog's very first post/tutorial I'll show how to model performance using the Banister impulse~response (IR) model.
output: html_document
bibliography: references.bib
csl: apa.csl
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In this blog’s very first post/tutorial I’ll show how to model the performance of several subjects using the Banister impulse~response (IR) model. Before starting I highly recommend checking out <a href="https://www.ncbi.nlm.nih.gov/pubmed/23728131">this</a> fantastic resource by <span class="citation">Clarke &amp; Skiba (2013)</span>, which I’ll be referencing a lot throughout this post. I also urge you to check out these posts ( <a href="https://complementarytraining.net/banister-impulseresponse-model-in-r/">here</a>, and <a href="https://complementarytraining.net/predicting-injuries-using-bannister-model/">here</a>) by Mladen Jovanovic, where he shares some very creative ideas on how to use Banister modelling for both performance and injury prediction. Lastly, the data we’ll be using can be found in <a href="https://www.nature.com/articles/srep40422">this</a> excellent article by Thierry <span class="citation">Busso (2017)</span>, who has done a lot of research into the modelling of the dose-response relationship between training and performance. A massive thanks to him and his contribution to open science!</p>
</div>
<div id="the-banister-impulseresponse-model" class="section level2">
<h2>The Banister impulse~response model</h2>
<p><span class="math inline">\(p(t) = p(0) + k_{1}\sum\limits_{s=0}^{t-1}e^{-(t-s)/t_1}w(s) + k_{2}\sum\limits_{s=0}^{t-1}e^{-(t-s)/t_2}w(s)\)</span></p>
<p>In simple terms, the Banister IR model quantitatively relates performance ability at a specific time to the cumulative effects of prior training loads <span class="citation">(Taha &amp; Thomas, 2003)</span>. Though the above equation looks rather intimidating at first, it’s actually quite easy to grasp once put in layman’s terms. First and foremost, the model posits that training will have both a positive (fitness) and a negative training effect (fatigue). Performance at a given time is thus simply the sum of base level performance plus the difference between the accumulated fitness and the accumulated fatigue. Other than being conceptually easy to understand, the model is also able to capture several phases related to the training process, including overreaching, plateau, taper, and detraining <span class="citation">(Clarke &amp; Skiba, 2013)</span>. Using athlete-specific data the model is easily fitted to individual athletes, making it a useful tool in the planning of training.</p>
</div>
<div id="fitting-the-model" class="section level2">
<h2>Fitting the model</h2>
<p>In contrast to the black box structure of neural networks, which I’ll cover in a separate post, the Banister IR model has five adjustable parameters. These include the initial performance level <span class="math inline">\(p(0)\)</span>, two time constants that describe the decay of the fitness and fatigue components <span class="math inline">\(k_1\)</span>, <span class="math inline">\(k_2\)</span>, and two gain parameters <span class="math inline">\(\tau_1\)</span>, <span class="math inline">\(\tau_2\)</span> that relate to how the training load determines the amplitude of fitness and fatigue. As showed by Clarke and Skiba (2011), these parameters can be easily fitted to data using nonlinear regression, which involves iteratively changing the parameters until the error between the model and the data is minimized. In the example below, we’re going to do this using R’s <em>optim</em> function.</p>
<div id="preparing-the-data" class="section level3">
<h3>Preparing the data</h3>
<p>To start off, let’s review the data:</p>
<pre class="r"><code>str(banister.data)</code></pre>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    109 obs. of  13 variables:
##  $ Day                         : num  1 2 3 4 5 6 7 8 9 10 ...
##  $ Training dose Subject 1 (tu): num  0 100 100 0 100 ...
##  $ Performance Subject 1 (Watt): num  NA 253 252 NA 245 NA NA 254 NA 258 ...
##  $ Training dose Subject 2 (tu): num  0 100 0 100 0 ...
##  $ Performance Subject 2 (Watt): num  NA 240 NA 236 NA 250 NA NA 244 NA ...
##  $ Training dose Subject 3 (tu): num  0 0 100 100 0 ...
##  $ Performance Subject 3 (Watt): num  NA NA 296 293 NA 284 NA NA 286 NA ...
##  $ Training dose Subject 4 (tu): num  0 0 100 100 0 ...
##  $ Performance Subject 4 (Watt): num  NA NA 300 291 NA 288 NA NA 296 299 ...
##  $ Training dose Subject 5 (tu): num  0 0 100 100 0 ...
##  $ Performance Subject 5 (Watt): num  NA NA 332 324 NA 332 NA NA 326 NA ...
##  $ Training dose Subject 6 (tu): num  0 0 100 100 0 ...
##  $ Performance Subject 6 (Watt): num  NA NA 218 231 NA 233 NA NA 232 NA ...</code></pre>
<p>As can be seen above, the data consists of training and testing data of six healthy male subjects over 15 weeks. The performance variable in this instance is the average power output over a 5-minute maximal cycling effort, while the training itself has been recorded in arbitrary units. Furthermore, the data has been coerced into a data frame with 13 columns and 109 observations. One column lists the number of days, while each consecutive column shows each participant’s performance and training dose. To make this data a little easier to work with we’re going to start by coercing it into six individual lists, one for each subject. This can easily be done by first subsetting the columns <em>Training dose</em> and <em>Performance</em> into two separate vectors. Next, we’re going to use a <em>for loop</em> to create six individual lists, each containing a data frame with a column for <em>Day</em>, <em>Training.Load</em>, and <em>Performance</em>. This can be done as follows:</p>
<pre class="r"><code>training &lt;- banister.data[seq(2, 13, by = 2)] #Subsets all the &#39;training dose&#39;  columns
performance &lt;- banister.data[seq(3, 13, by = 2)] #Subsets all the &#39;performance&#39; columns
banister.list &lt;- vector(&quot;list&quot;, 6) #Creates an empty list vector

for (i in 1:6) {
  banister.list[i] &lt;- list(cbind(banister.data[1], training[i], performance[i])) 
}
names(banister.list) &lt;- paste(&quot;Subject&quot;, 1:6, sep =&quot;&quot;) #Sets the name of each data frame in the list to &#39;Athlete1&#39;, 2, etc
banister.list &lt;- lapply(banister.list, function(x) { #Sets the name of each column within the data frames
  colnames(x) &lt;- c(&quot;Day&quot;, &quot;Training.Load&quot;, &quot;Performance&quot;)
  return(x)
})

str(banister.list)</code></pre>
<pre><code>## List of 6
##  $ Subject1:&#39;data.frame&#39;:    109 obs. of  3 variables:
##   ..$ Day          : num [1:109] 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ Training.Load: num [1:109] 0 100 100 0 100 ...
##   ..$ Performance  : num [1:109] NA 253 252 NA 245 NA NA 254 NA 258 ...
##  $ Subject2:&#39;data.frame&#39;:    109 obs. of  3 variables:
##   ..$ Day          : num [1:109] 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ Training.Load: num [1:109] 0 100 0 100 0 ...
##   ..$ Performance  : num [1:109] NA 240 NA 236 NA 250 NA NA 244 NA ...
##  $ Subject3:&#39;data.frame&#39;:    109 obs. of  3 variables:
##   ..$ Day          : num [1:109] 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ Training.Load: num [1:109] 0 0 100 100 0 ...
##   ..$ Performance  : num [1:109] NA NA 296 293 NA 284 NA NA 286 NA ...
##  $ Subject4:&#39;data.frame&#39;:    109 obs. of  3 variables:
##   ..$ Day          : num [1:109] 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ Training.Load: num [1:109] 0 0 100 100 0 ...
##   ..$ Performance  : num [1:109] NA NA 300 291 NA 288 NA NA 296 299 ...
##  $ Subject5:&#39;data.frame&#39;:    109 obs. of  3 variables:
##   ..$ Day          : num [1:109] 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ Training.Load: num [1:109] 0 0 100 100 0 ...
##   ..$ Performance  : num [1:109] NA NA 332 324 NA 332 NA NA 326 NA ...
##  $ Subject6:&#39;data.frame&#39;:    109 obs. of  3 variables:
##   ..$ Day          : num [1:109] 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ Training.Load: num [1:109] 0 0 100 100 0 ...
##   ..$ Performance  : num [1:109] NA NA 218 231 NA 233 NA NA 232 NA ...</code></pre>
</div>
<div id="writing-the-ir-function" class="section level3">
<h3>Writing the IR function</h3>
<p>Now that the data is neatly structured, we can start thinking about ways to write the IR function. If we look at the R Documentation for the <em>optim</em> function (which can be done by typing ?optim in the console), we can see that the first argument of our IR function needs to contain a vector with the parameters we want to optimize for. In our case this will be the five adjustible parameters associated with the IR model: the initial performance level <span class="math inline">\(p(0)\)</span>, the two time constants (<span class="math inline">\(k_1\)</span>, <span class="math inline">\(k_2\)</span>), and the two gain parameters (<span class="math inline">\(\tau_1\)</span>, <span class="math inline">\(\tau_2\)</span>). Also, although I referenced the summation equation of the IR model previously, we’re going to follow the example of <span class="citation">Clarke &amp; Skiba (2013)</span> and use a set of recursion equations instead. These can be seen in the code chunk below. Lastly, to fit a model for each subject we need to minimize the error between predicted performance and actual performance. To do this we’ll use the sum of squared errors as the metric to be minimised.</p>
<pre class="r"><code>banister.function &lt;- function (v, Training.Load, Performance) { #The function takes three inputs...
  p0 &lt;- v[1]; k1 &lt;- v[2]; k2 &lt;- v[3]; tau1 &lt;- v[4]; tau2 &lt;- v[5]
  Fitness &lt;- 0
  Fatigue &lt;- 0
  for (i in 1:length(Training.Load)) {
    Fitness[i+1] &lt;- Fitness[i] * exp(-1/tau1) + Training.Load[i+1] #Recursion equations
    Fatigue[i+1] &lt;- Fatigue[i] * exp(-1/tau2) + Training.Load[i+1] 
    Predicted.Performance &lt;- p0 + k1*Fitness - k2*Fatigue
  }
  errors &lt;- Performance[!is.na(Performance)] - Predicted.Performance[which(!is.na(Performance))]  
  SSE &lt;- sum(errors^2)
  return(SSE) #...and returns the sum of squared errors
}</code></pre>
</div>
<div id="optimizing-parameters-for-each-subject" class="section level3">
<h3>Optimizing parameters for each subject</h3>
<p>Now that we have created our IR function we can use <em>lapply</em> to apply said function over the data for each subject. This in turn will create six optimized sets of parameters, one for each subject. However, before running the function, we have to set our initial parameter values. In this case, I’ve used <span class="math inline">\(p(0) = 256\)</span>, <span class="math inline">\(k_1 = 0.10\)</span>, <span class="math inline">\(k_2 = 0.10\)</span>, <span class="math inline">\(\tau_1 = 15\)</span>, and <span class="math inline">\(\tau_2 = 11\)</span>.</p>
<pre class="r"><code>banister.optimised &lt;- vector(&quot;list&quot;, 6)

for (j in 1:6) {
  banister.optimised[[j]] &lt;- optim(par = c(256, 0.10, 0.10, 15, 11), fn = banister.function, Training.Load = banister.list[[j]][,2], Performance = banister.list[[j]][,3])
}  

names(banister.optimised) &lt;- paste(&quot;Subject&quot;, 1:6, sep = &quot;&quot;)

str(banister.optimised[1])</code></pre>
<pre><code>## List of 1
##  $ Subject1:List of 5
##   ..$ par        : num [1:5] 256.95 0.137 0.135 14.373 11.382
##   ..$ value      : num 3145
##   ..$ counts     : Named int [1:2] 501 NA
##   .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;function&quot; &quot;gradient&quot;
##   ..$ convergence: int 1
##   ..$ message    : NULL</code></pre>
<p>The output above shows a list of components generated by the <em>optim</em> function for Subject1. Two of these components are of special interest to us: <em>par</em> and <em>value</em>. The <em>par</em> component shows the optimized parameter values for the given athlete, while the <em>value</em> component shows the sum of squared errors. Let’s create a new list with these components alongside <em>Day</em>, <em>Training.Load</em>, and <em>Performance</em>.</p>
<pre class="r"><code>banister.parameters &lt;- vector(&quot;list&quot;, 6)
for (i in 1:6) {
  banister.parameters[[i]] &lt;- list(&quot;Day&quot; = banister.list[[i]][,1], &quot;Training.Load&quot; = banister.list[[i]][,2], &quot;Performance&quot; = banister.list[[i]][,3], &quot;Parameters&quot; = banister.optimised[[i]]$par, &quot;SSE&quot; = banister.optimised[[i]]$value)
}

names(banister.parameters) &lt;- paste(&quot;Subject&quot;, 1:6, sep = &quot;&quot;)

str(banister.parameters[1])</code></pre>
<pre><code>## List of 1
##  $ Subject1:List of 5
##   ..$ Day          : num [1:109] 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ Training.Load: num [1:109] 0 100 100 0 100 ...
##   ..$ Performance  : num [1:109] NA 253 252 NA 245 NA NA 254 NA 258 ...
##   ..$ Parameters   : num [1:5] 256.95 0.137 0.135 14.373 11.382
##   ..$ SSE          : num 3145</code></pre>
</div>
<div id="creating-models" class="section level3">
<h3>Creating models</h3>
<p>Now that we have opimized each athletes parameters, and organised the metrics into neatly organised lists, we can use the magic that is <em>lapply</em> to create six individual models.</p>
<pre class="r"><code>banister.models &lt;- lapply(banister.parameters, function(x) {
  p0 &lt;- x$Parameters[1]; k1 &lt;- x$Parameters[2]; k2 &lt;- x$Parameters[3]; tau1 &lt;- x$Parameters[4]; tau2 &lt;- x$Parameters[5]
  Fitness &lt;- 0
  Fatigue &lt;- 0
  for (i in 1:length(x$Training.Load)) {
    Fitness[i+1] &lt;- Fitness[i] * exp(-1/tau1) + x$Training.Load[i+1]
    Fatigue[i+1] &lt;- Fatigue[i] * exp(-1/tau2) + x$Training.Load[i+1]
    Predicted.Performance &lt;- p0 + k1*Fitness - k2*Fatigue
  }
  Errors &lt;- x$Performance[!is.na(x$Performance)] - Predicted.Performance[which(!is.na(x$Performance))]
  SSE &lt;- sum(Errors^2)
  R.2 &lt;- (cor(x$Performance[!is.na(x$Performance)], Predicted.Performance[which(!is.na(x$Performance))]))^2
  return(list(&quot;Day&quot; = x$Day, &quot;Training.Load&quot; = x$Training.Load, &quot;Performance&quot; = x$Performance, &quot;Predicted.Performance&quot; = Predicted.Performance[!is.na(Predicted.Performance)], &quot;SSE&quot; = SSE ,&quot;R.2&quot; = R.2))
})</code></pre>
<p>As shown below the individual <span class="math inline">\(r^2\)</span> values ranges from 0.86 to 0.95, indicating that the models fit nicely to the data.</p>
<pre><code>## $Subject1
## [1] 0.9305551
## 
## $Subject2
## [1] 0.8805885
## 
## $Subject3
## [1] 0.9472296
## 
## $Subject4
## [1] 0.8595214
## 
## $Subject5
## [1] 0.9485933
## 
## $Subject6
## [1] 0.9060418</code></pre>
</div>
<div id="visualization" class="section level3">
<h3>Visualization</h3>
<p>Now that we have six nicely fitted models we can start thinking about ways to visualize them. A great package to do this is <em>ggplot</em>, however <em>ggplot</em> only take dataframes as inputs. We therefore first have to transform our lists into dataframes. We’re also going to create a new variable called <em>‘Week’</em> to visualize the weekly progression in performance rather than day by day. To do this we’re going to use <em>dplyr</em>:</p>
<pre class="r"><code>banister.models &lt;- lapply(banister.models, function(x) {
  x$Week &lt;- x$Day/7
  return(x) #Creates a variable called &#39;Week&#39;
})

banister.df &lt;- plyr::ldply(banister.models, data.frame)

colnames(banister.df)[colnames(banister.df)==&quot;.id&quot;] &lt;- &quot;Subject&quot;

banister.plots &lt;- ggplot(banister.df, aes(x = Week, y = Predicted.Performance)) +
  geom_line(aes(y = Predicted.Performance, colour = &quot;black&quot;), size = 1) +
  geom_point(aes(y = Performance, colour = &quot;red&quot;), shape = 1) +
  scale_color_manual(&quot;&quot;, values = c(&quot;black&quot;, &quot;red&quot;), labels = c(&quot;Predicted Performance&quot;, &quot;Actual Performance&quot;)) +
  guides(colour = guide_legend(override.aes = list(linetype = c(&quot;solid&quot;, &quot;blank&quot;), shape = c(NA, 1)))) +
  ylab(&quot;Performance&quot;) +
  xlab(&quot;Week&quot;) +
  scale_x_continuous(breaks = seq(0,16,2)) +
  geom_label(data = banister.df, aes(x = 2, y = 400, label = paste(&quot;italic(R) ^ 2 == &quot;, round(R.2, 2))), parse = TRUE, size = 3) +
  theme_minimal() +
  facet_wrap(~ Subject, ncol = 2) 

banister.plots</code></pre>
<p><img src="/post/banister-model/Banister-doc_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="final-notes" class="section level1">
<h1>Final notes</h1>
<p>And there you have it. The plot above shows how each subject’s performance capacity changes over time as a function of training. This underlines the usefuleness of the original Banister IR model as an excellent gateway into performance modelling and as a useful pedagogical tool within sports and exercise science <span class="citation">(Clarke &amp; Skiba, 2013)</span>. In later blog posts I’ll show a couple of extensions to the IR and model, and maybe compare it to some modern neural networks. Stay tuned.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-busso2017indirect">
<p>Busso, T. (2017). From an indirect response pharmacodynamic model towards a secondary signal model of dose-response relationship between exercise training and physical performance. <em>Scientific Reports</em>, <em>7</em>, 40422.</p>
</div>
<div id="ref-clarke2013rationale">
<p>Clarke, D. C., &amp; Skiba, P. F. (2013). Rationale and resources for teaching the mathematical modeling of athletic training and performance. <em>Advances in Physiology Education</em>, <em>37</em>(2), 134–152.</p>
</div>
<div id="ref-taha2003systems">
<p>Taha, T., &amp; Thomas, S. G. (2003). Systems modelling of the relationship between training and performance. <em>Sports Medicine</em>, <em>33</em>(14), 1061–1073.</p>
</div>
</div>
</div>
