---
title: "Fitting individualized impulse~response models in R"
author: "Andreas K. Winther"
date: "02/03/2019"
output: html_document
bibliography: references.bib
csl: apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Introduction

In this blog's very first post/tutorial we’re going to try and model the performance of several subjects using the Banister impulse~response (IR) model. Before starting I highly recommend checking out [this](https://www.ncbi.nlm.nih.gov/pubmed/23728131) fantastic resource by @clarke2013rationale, which I’ll be referencing a lot throughout this post. I also urge you to check out these posts ( [here](https://complementarytraining.net/banister-impulseresponse-model-in-r/), and [here](https://complementarytraining.net/predicting-injuries-using-bannister-model/)) by Mladen Jovanovic, where he shares some very creative ideas on how to use Banister modelling for both performance and injury prediction. Lastly, the data we’ll be using can be found in [this](https://www.nature.com/articles/srep40422) excellent article by Thierry @busso2017indirect, who has done a lot of research into the modelling of the dose-response relationship between training and performance. A massive thanks to him and his contribution to open science!

##The Banister impulse~response model

$p(t) = p(0) + k_{1}\sum\limits_{s=0}^{t-1}e^{-(t-s)/t_1}w(s) + k_{2}\sum\limits_{s=0}^{t-1}e^{-(t-s)/t_2}w(s)$

In simple terms, the Banister IR model quantitatively relates performance ability at a specific time to the cumulative effects of prior training loads [@taha2003systems]. Though the above equation looks rather intimidating at first, it’s actually quite easy to grasp once put in layman’s terms. First and foremost, the model posits that training will have both a positive (fitness) and a negative training effect (fatigue). Performance at a given time is thus simply the sum of base level performance plus the difference between the accumulated fitness and the accumulated fatigue. Other than being conceptually easy to understand, the model is also able to capture several phases related to the training process, including overreaching, plateau, taper, and detraining [@clarke2013rationale]. Using athlete-specific data the model is easily fitted to individual athletes, making it a useful tool in the planning of training.   

##Fitting the model 

In contrast to the black box structure of neural networks, which I’ll cover in a separate post, the Banister IR model has five adjustable parameters. These include the initial performance level $p(0)$, two time constants that describe the decay of the fitness and fatigue components $k_1$, $k_2$, and two gain parameters $\tau_1$, $\tau_2$ that relate to how the training load determines the amplitude of fitness and fatigue. As showed by Clarke and Skiba (2011), these parameters can be easily fitted to data using nonlinear regression, which involves iteratively changing the parameters until the error between the model and the data is minimized. In the example below, we’re going to do this using R’s *optim* function.  

###Preparing the data

To start off, let's review the data:        
```{r echo=FALSE, message=FALSE}
library(readxl)
library(ggplot2)
library(dplyr)
```
```{r echo=FALSE}
banister.data <- read_excel("C:/Users/Andreas/SkyDrive/Dokumenter/ModellingInR/Busso2017su1.xlsx")
```
```{r}
str(banister.data)
```

As can be seen above, the data consists of training and testing data of six healthy male subjects over 15 weeks. The performance variable in this instance is the average power output over a 5-minute maximal cycling effort, while the training itself has been recorded in arbitrary units. Furthermore, the data has been coerced into a data frame with 13 columns and 109 observations. One column lists the number of days, while each consecutive column shows each participant's performance and training dose. To make this data a little easier to work with we're going to start by coercing it into six individual lists, one for each subject. This can easily be done by first subsetting the columns *Training dose* and *Performance* into two separate vectors. Next, we're going to use a *for loop* to create six individual lists, each containing a data frame with a column for *Day*, *Training.Load*, and *Performance*. This can be done as follows:
```{r}
training <- banister.data[seq(2, 13, by = 2)] #Subsets all the 'training dose'  columns
performance <- banister.data[seq(3, 13, by = 2)] #Subsets all the 'performance' columns
banister.list <- vector("list", 6) #Creates an empty list vector

for (i in 1:6) {
  banister.list[i] <- list(cbind(banister.data[1], training[i], performance[i])) 
}
names(banister.list) <- paste("Subject", 1:6, sep ="") #Sets the name of each data frame in the list to 'Athlete1', 2, etc
banister.list <- lapply(banister.list, function(x) { #Sets the name of each column within the data frames
  colnames(x) <- c("Day", "Training.Load", "Performance")
  return(x)
})

str(banister.list)
```

###Writing the IR function
Now that we have our data neatly structured, we can start thinking about ways to write our IR function. If we look at the R Documentation for the *optim* function (which can be done by typing ?optim in the console), we can see that the first argument of our IR function needs to contain a vector with the parameters we want to optimize for. In our case this will be the five adjustible parameters associated with the IR model: the initial performance level $p(0)$, the two time constants ($k_1$, $k_2$), and the two gain parameters ($\tau_1$, $\tau_2$). Also, although the the summation equation of the IR model was referenced previously, we're going to follow the example of @clarke2013rationale and use a set of recursion equations instead. These can be seen in the code chunk below. Lastly, to fit a model for each subject we need to minimize the error between predicted performance and actual performance. To do this we'll use the sum of squared errors as the metric to be minimised. 
```{r}
banister.function <- function (v, Training.Load, Performance) { #The function takes three inputs...
  p0 <- v[1]; k1 <- v[2]; k2 <- v[3]; tau1 <- v[4]; tau2 <- v[5]
  Fitness <- 0
  Fatigue <- 0
  for (i in 1:length(Training.Load)) {
    Fitness[i+1] <- Fitness[i] * exp(-1/tau1) + Training.Load[i+1] #Recursion equations
    Fatigue[i+1] <- Fatigue[i] * exp(-1/tau2) + Training.Load[i+1] 
    Predicted.Performance <- p0 + k1*Fitness - k2*Fatigue
  }
  errors <- Performance[!is.na(Performance)] - Predicted.Performance[which(!is.na(Performance))]  
  SSE <- sum(errors^2)
  return(SSE) #...and returns the sum of squared errors
}
```

###Optimizing parameters for each subject
Now that we have created our IR function we can use *lapply* to apply said function over the data for each subject. This in turn will create six optimized sets of parameters, one for each subject. However, before running the function, we have to set our initial parameter values. In this case, I've used $p(0) = 256$, $k_1 = 0.10$, $k_2 = 0.10$, $\tau_1 = 15$, and $\tau_2 = 11$. 
```{r}
banister.optimised <- vector("list", 6)

for (j in 1:6) {
  banister.optimised[[j]] <- optim(par = c(256, 0.10, 0.10, 15, 11), fn = banister.function, Training.Load = banister.list[[j]][,2], Performance = banister.list[[j]][,3])
}  

names(banister.optimised) <- paste("Subject", 1:6, sep = "")

str(banister.optimised[1])
```
The output above shows a list of components generated by the *optim* function for Subject1. Two of these components are of special interest to us: *par* and *value*. The *par* component shows the optimized parameter values for the given athlete, while the *value* component shows the sum of squared errors. Let's create a new list with these components alongside *Day*, *Training.Load*, and *Performance*.
```{r}
banister.parameters <- vector("list", 6)
for (i in 1:6) {
  banister.parameters[[i]] <- list("Day" = banister.list[[i]][,1], "Training.Load" = banister.list[[i]][,2], "Performance" = banister.list[[i]][,3], "Parameters" = banister.optimised[[i]]$par, "SSE" = banister.optimised[[i]]$value)
}

names(banister.parameters) <- paste("Subject", 1:6, sep = "")

str(banister.parameters[1])
```

###Creating models
Now that we have opimized each athletes parameters, and organised the metrics into neatly organised lists, we can use the magic that is *lapply* to create six individual models. 
```{r}
banister.models <- lapply(banister.parameters, function(x) {
  p0 <- x$Parameters[1]; k1 <- x$Parameters[2]; k2 <- x$Parameters[3]; tau1 <- x$Parameters[4]; tau2 <- x$Parameters[5]
  Fitness <- 0
  Fatigue <- 0
  for (i in 1:length(x$Training.Load)) {
    Fitness[i+1] <- Fitness[i] * exp(-1/tau1) + x$Training.Load[i+1]
    Fatigue[i+1] <- Fatigue[i] * exp(-1/tau2) + x$Training.Load[i+1]
    Predicted.Performance <- p0 + k1*Fitness - k2*Fatigue
  }
  Errors <- x$Performance[!is.na(x$Performance)] - Predicted.Performance[which(!is.na(x$Performance))]
  SSE <- sum(Errors^2)
  R.2 <- (cor(x$Performance[!is.na(x$Performance)], Predicted.Performance[which(!is.na(x$Performance))]))^2
  return(list("Day" = x$Day, "Training.Load" = x$Training.Load, "Performance" = x$Performance, "Predicted.Performance" = Predicted.Performance[!is.na(Predicted.Performance)], "SSE" = SSE ,"R.2" = R.2))
})

```
As shown below the individual $r^2$ values ranges from 0.86 to 0.95, indicating that the models fit nicely to the data.
```{r echo = FALSE}
lapply(banister.models, function(x) {
  return(x$R.2)
})
```

###Visualization
Now that we have six nicely fitted models we can start thinking about ways to visualize them. A great package to do this is *ggplot*, however *ggplot* only takes dataframes as inputs. We therefore first have to transform our lists into dataframes. We're also going to create a new variable called *'Week'* to visualize the weekly progression in performance rather than day by day. To do this we're going to use *dplyr*: 
```{r warning = FALSE}
banister.models <- lapply(banister.models, function(x) {
  x$Week <- x$Day/7
  return(x) #Creates a variable called 'Week'
})

banister.df <- plyr::ldply(banister.models, data.frame)

colnames(banister.df)[colnames(banister.df)==".id"] <- "Subject"

banister.plots <- ggplot(banister.df, aes(x = Week, y = Predicted.Performance)) +
  geom_line(aes(y = Predicted.Performance, colour = "black"), size = 1) +
  geom_point(aes(y = Performance, colour = "red"), shape = 1) +
  scale_color_manual("", values = c("black", "red"), labels = c("Predicted Performance", "Actual Performance")) +
  guides(colour = guide_legend(override.aes = list(linetype = c("solid", "blank"), shape = c(NA, 1)))) +
  ylab("Performance") +
  xlab("Week") +
  scale_x_continuous(breaks = seq(0,16,2)) +
  geom_label(data = banister.df, aes(x = 2, y = 400, label = paste("italic(R) ^ 2 == ", round(R.2, 2))), parse = TRUE, size = 3) +
  theme_minimal() +
  facet_wrap(~ Subject, ncol = 2) 

banister.plots
```

#Final notes
And there you have it. The plot above shows how each subject's performance capacity changes over time as a function of training. This underlines the usefuleness of the original Banister IR model as an excellent gateway into performance modelling and as a useful pedagogical tool within sports and exercise science [@clarke2013rationale]. In later blog posts I'll show a couple of extensions to the IR and model, and maybe compare it to some modern neural networks. Stay tuned. 

#References